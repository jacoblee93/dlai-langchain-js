{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain.js\n",
    "\n",
    "# Building Blocks: LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Sure, here's a classic one for you:\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Why don't scientists trust atoms?\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Because they make up everyth\"\u001b[39m... 4 more characters,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m }\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain\"\u001b[39m, \u001b[32m\"schema\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Sure, here's a classic one for you:\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Why don't scientists trust atoms?\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Because they make up everyth\"\u001b[39m... 4 more characters,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deno.env.set(\"OPENAI_API_KEY\", \"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\")\n",
    "\n",
    "import { ChatOpenAI } from \"npm:langchain@0.0.178/chat_models/openai\";\n",
    "import { HumanMessage } from \"npm:langchain@0.0.178/schema\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-3.5-turbo\",\n",
    "});\n",
    "\n",
    "await model.invoke([\n",
    "  new HumanMessage(\"Tell me a joke\")\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Blocks: Prompt Template\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"npm:langchain@0.0.178/prompts\";\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromTemplate(\n",
    "  `What are three good names for a company that makes {product}`\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Human: What are three good names for a company that makes colorful socks\"\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await prompt.format({\n",
    "  product: \"colorful socks\"\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "    lc_kwargs: {\n",
       "      content: \u001b[32m\"What are three good names for a company that makes colorful socks\"\u001b[39m,\n",
       "      additional_kwargs: {}\n",
       "    },\n",
       "    lc_namespace: [ \u001b[32m\"langchain\"\u001b[39m, \u001b[32m\"schema\"\u001b[39m ],\n",
       "    content: \u001b[32m\"What are three good names for a company that makes colorful socks\"\u001b[39m,\n",
       "    name: \u001b[90mundefined\u001b[39m,\n",
       "    additional_kwargs: {}\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await prompt.formatMessages({\n",
    "  product: \"colorful socks\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Blocks: LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "const chain = prompt.pipe(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"1. Rainbow Threads\\n2. Chroma Sox\\n3. Vivid Hues\"\u001b[39m,\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m }\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain\"\u001b[39m, \u001b[32m\"schema\"\u001b[39m ],\n",
       "  content: \u001b[32m\"1. Rainbow Threads\\n2. Chroma Sox\\n3. Vivid Hues\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.invoke({\n",
    "  product: \"colorful socks\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Blocks: Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StringOutputParser } from \"npm:langchain@0.0.178/schema/output_parser\";\n",
    "\n",
    "const outputParser = new StringOutputParser();\n",
    "\n",
    "const nameGenerationChain = prompt.pipe(model).pipe(outputParser);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"1. Divine Delights\\n2. Gourmet Crumbs\\n3. Elegant Bites\"\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await nameGenerationChain.invoke({\n",
    "  product: \"fancy cookies\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      ".\n",
      " Rob\n",
      "o\n",
      "Tech\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " Mech\n",
      "M\n",
      "akers\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " Fut\n",
      "ur\n",
      "Bot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const stream = await nameGenerationChain.stream({\n",
    "  product: \"really cool robots\"\n",
    "});\n",
    "\n",
    "for await (const chunk of stream) {\n",
    "  console.log(chunk);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response {\n",
       "  body: IterableReadableStream { locked: false },\n",
       "  bodyUsed: false,\n",
       "  headers: Headers {},\n",
       "  ok: true,\n",
       "  redirected: false,\n",
       "  status: 200,\n",
       "  statusText: \"\",\n",
       "  url: \"\"\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { BytesOutputParser } from \"npm:langchain@0.0.178/schema/output_parser\";\n",
    "\n",
    "const stream = await nameGenerationChain.stream({\n",
    "  product: \"superb owls\",\n",
    "});\n",
    "\n",
    "new Response(stream);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining with `RunnableMap`\n",
    "\n",
    "(Add slide/visual to demonstrate what's going on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableSequence, RunnableMap } from \"npm:langchain@0.0.178/schema/runnable\";\n",
    "\n",
    "const finalPrompt = ChatPromptTemplate.fromTemplate(\n",
    "  `Pick the best name from {names} based on {final_criteria} and explain why.`\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "const decisionChain = finalPrompt.pipe(model).pipe(new StringOutputParser());\n",
    "\n",
    "// nameGenerationChain.pipe(decisionChain)\n",
    "const initialStep = RunnableMap.from({\n",
    "  names: nameGenerationChain,\n",
    "  final_criteria: (input) => input.final_criteria,\n",
    "});\n",
    "\n",
    "const combinedChain = initialStep.pipe(decisionChain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m'Based on sustainability, the best name from the provided options would be \"WoodCraft Motors.\"\\n'\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"1. Ti\"\u001b[39m... 784 more characters"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await combinedChain.invoke({\n",
    "  product: \"wooden cars\",\n",
    "  final_criteria: \"sustainability\",\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
