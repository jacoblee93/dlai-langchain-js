{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval chains\n",
    "\n",
    "Now, we'll combine the basic Expression Language building blocks, document loading and splitting, and vectorstores to create a retrieval chain that can\n",
    "perform the last two steps of the RAG process:\n",
    "\n",
    "![](./static/images/rag_diagram.png)\n",
    "\n",
    "This chain will retrieve chunks that are most similar to the input query, then will present them to the LLM as context to ground the LLM's generation of a final answer.\n",
    "\n",
    "// Start with high level steps + overview of what's to come\n",
    "\n",
    "To start, let's split and load the CS229 lesson PDF transcript from earlier. We'll use bigger chunks this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] { default: {} }"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \"npm:dotenv/config\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Peer dependency\n",
    "import * as parse from \"npm:pdf-parse\";\n",
    "import { PDFLoader } from \"npm:langchain@0.0.201/document_loaders/fs/pdf\";\n",
    "import { RecursiveCharacterTextSplitter } from \"npm:langchain@0.0.201/text_splitter\";\n",
    "\n",
    "const loader = new PDFLoader(\"./static/docs/MachineLearning-Lecture01.pdf\");\n",
    "\n",
    "const rawCS229Docs = await loader.load();\n",
    "\n",
    "const splitter = new RecursiveCharacterTextSplitter({\n",
    "  chunkSize: 1536,\n",
    "  chunkOverlap: 128,\n",
    "});\n",
    "\n",
    "const splitDocs = await splitter.splitDocuments(rawCS229Docs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Make sure you explain chunkOverlap\n",
    "\n",
    "Now, let's load those docs into a vectorstore the same way we did in the previous lesson using OpenAI embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MemoryVectorStore } from \"npm:langchain@0.0.201/vectorstores/memory\";\n",
    "import { OpenAIEmbeddings } from \"npm:langchain@0.0.201/embeddings/openai\";\n",
    "\n",
    "const embeddings = new OpenAIEmbeddings();\n",
    "\n",
    "const vectorstore = new MemoryVectorStore(embeddings);\n",
    "\n",
    "await vectorstore.addDocuments(splitDocs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll create a `retriever` from that vectorstore that will fetch the documents for a given natural language query. There are other types of document fetchers other than vectorstores, which is why it's nicer to have a more abstract interface:\n",
    "\n",
    "// Let's mention it's a runnable here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const retriever = vectorstore.asRetriever();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to start constructing our retrieval chain!\n",
    "\n",
    "Retrievers take a string as direct input to the retriever, but we often find it convenient to have chains take an object parameter for flexibility.\n",
    "So let's start by creating a simple sequence that will take an object with a field called `question`, and formats the resulting documents' page content as strings. We'll use <doc></doc> XML-esque tags to separate the contents of each for clarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc>\n",
      "of this class will not be very program ming intensive, although we will do some  \n",
      "programming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.   \n",
      "I also assume familiarity with basic proba bility and statistics. So most undergraduate  \n",
      "statistics class, like Stat 116 taught here at  Stanford, will be more than enough. I'm gonna  \n",
      "assume all of you know what ra ndom variables are,  that all of you know  what expectation  \n",
      "is, what a variance or a random variable is.  And in case of some of you, it's been a while  \n",
      "since you've seen some of this material. At  some of the discussion sections, we'll actually  \n",
      "go over some of the prerequisites, sort of as  a refresher course under prerequisite class.  \n",
      "I'll say a bit more about  that later as well.   \n",
      "Lastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate  \n",
      "linear algebra courses are more than enough.  So if you've taken courses like Math 51,  \n",
      "103, Math 113 or CS205 at Stanford, that  would be more than enough. Basically, I'm  \n",
      "gonna assume that all of you know what matrix es and vectors are, that you know how to  \n",
      "multiply matrices and vectors and multiply matrix and matrices, that you know what a  \n",
      "matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better.  \n",
      "But if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in  \n",
      "the review sections.\n",
      "</doc>\n",
      "<doc>\n",
      "refresher for those of you that want one.   \n",
      "Later in this quarter, we'll also use the disc ussion sections to go over extensions for the  \n",
      "material that I'm teaching in the main lectur es. So machine learning is a huge field, and  \n",
      "there are a few extensions that we really want  to teach but didn't have time in the main  \n",
      "lectures for.\n",
      "</doc>\n",
      "<doc>\n",
      "But if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in  \n",
      "the review sections.   \n",
      "So there are a couple more logisti cal things I should deal with in  this class. One is that, as  \n",
      "most of you know, CS229 is a televised cla ss. And in fact, I guess many of you are  \n",
      "probably watching this at home on TV, so I' m gonna say hi to our home viewers.   \n",
      "So earlier this year, I appro ached SCPD, which televises th ese classes, about trying to  \n",
      "make a small number of Stanford classes publ icly available or posting the videos on the  \n",
      "web. And so this year, Stanford is actually  starting a small pilot program in which we'll  \n",
      "post videos of a small number of classes onlin e, so on the Internet in a way that makes it  \n",
      "publicly accessible to everyone. I'm very exc ited about that because machine learning in  \n",
      "school, let's get the word out there.   \n",
      "One of the consequences of this  is that — let's see — so videos  or pictures of the students  \n",
      "in this classroom will not be  posted online, so your images — so don't worry about being  \n",
      "by seeing your own face appear on YouTube one day. But the microphones may pick up  \n",
      "your voices, so I guess the consequence of that is that because microphones may pick up  \n",
      "your voices, no matter how irritated you are at  me, don't yell out swear words in the  \n",
      "middle of class, but because there won't be  video you can safely sit there and make faces  \n",
      "at me, and that won't show, okay?\n",
      "</doc>\n",
      "<doc>\n",
      "So in this class, we've tried to convey to  you a broad set of principl es and tools that will  \n",
      "be useful for doing many, many things. And ev ery time I teach this class, I can actually  \n",
      "very confidently say that af ter December, no matter what yo u're going to do after this  \n",
      "December when you've sort of completed this  class, you'll find the things you learn in  \n",
      "this class very useful, and these things will  be useful pretty much no matter what you end  \n",
      "up doing later in your life.   \n",
      "So I have more logistics to go over later,  but let's say a few more words about machine  \n",
      "learning. I feel that machine learning grew out of  early work in AI, early work in artificial  \n",
      "intelligence. And over the last — I wanna say last 15 or last 20 years or so, it's been  \n",
      "viewed as a sort of growing  new capability for computers. And in particular, it turns out  \n",
      "that there are many programs or there are  many applications that you can't program by  \n",
      "hand.   \n",
      "For example, if you want to get a computer to  read handwritten characters, to read sort of  \n",
      "handwritten digits, that actual ly turns out to be amazingly difficult to write a piece of  \n",
      "software to take this input, an image of some thing that I wrote and to  figure out just what  \n",
      "it is, to translate my cursive handwriting into  — to extract the characters I wrote out in  \n",
      "longhand. And other things: One thing that my  students and I do is autonomous flight. It  \n",
      "turns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.\n",
      "</doc>\n"
     ]
    }
   ],
   "source": [
    "import { RunnableSequence } from \"npm:langchain@0.0.201/schema/runnable\";\n",
    "import { Document } from \"npm:langchain@0.0.201/document\";\n",
    "\n",
    "const convertDocsToString = (documents: Document[]): string => {\n",
    "  return documents.map((document) => `<doc>\\n${document.pageContent}\\n</doc>`).join(\"\\n\");\n",
    "};\n",
    "\n",
    "const documentRetrievalChain = RunnableSequence.from([\n",
    "  (input) => input.question,\n",
    "  retriever,\n",
    "  convertDocsToString,\n",
    "]);\n",
    "\n",
    "const results = await documentRetrievalChain.invoke({\n",
    "  question: \"What are the prerequisites for this course?\"\n",
    "});\n",
    "\n",
    "console.log(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like that contains the raw information! Now, let's construct a chain that synthesizes that information into a concise response. We'll start with a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate } from \"npm:langchain@0.0.200/prompts\";\n",
    "\n",
    "const TEMPLATE_STRING = `You are an experienced researcher, expert at interpreting and answering questions based on provided sources.\n",
    "Using the provided context, answer the user's question to the best of your ability using only the resources provided. Be concise!\n",
    "\n",
    "<context>\n",
    "\n",
    "{context}\n",
    "\n",
    "</context>\n",
    "\n",
    "Now, answer this question using the above context:\n",
    "\n",
    "{question}`;\n",
    "\n",
    "const answerGenerationPrompt = ChatPromptTemplate.fromTemplate(TEMPLATE_STRING);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put that together with our document retrieval sequence!\n",
    "\n",
    "One thing to note here is that our prompt requires an object with a `context` property as argument, while our previously defined `documentRetrievalChain` outputs a string. To make the arguments match, we use a `RunnableMap`. When a `RunnableMap` is invoked, it calls all runnables or runnable-like objects that it has as properties in parallel, invoking each with the input to the map. Then outputs an object whose properties are the results of those calls:\n",
    "\n",
    "// Add picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  question: \u001b[32m\"What are the prerequisites for this course?\"\u001b[39m,\n",
       "  context: \u001b[32m\"<doc>\\n\"\u001b[39m +\n",
       "    \u001b[32m\"of this class will not be very program ming intensive, although we will do some  \\n\"\u001b[39m +\n",
       "    \u001b[32m\"programming,\"\u001b[39m... 4728 more characters\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { RunnableMap } from \"npm:langchain@0.0.201/schema/runnable\";\n",
    "\n",
    "const runnableMap = RunnableMap.from({\n",
    "  context: documentRetrievalChain,\n",
    "  question: (input) => input.question,\n",
    "});\n",
    "\n",
    "await runnableMap.invoke({ question: \"What are the prerequisites for this course?\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, `documentRetrievalChain` is invoked with the object `{ question: \"What are the prerequisites for this course?\" }`, which results in the `documentRetrievalChain`'s output as a property names `context`. And that's the format we need to pass to our prompt! Let's see what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"npm:langchain@0.0.201/chat_models/openai\";\n",
    "import { StringOutputParser } from \"npm:langchain@0.0.201/schema/output_parser\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-3.5-turbo-1106\",\n",
    "});\n",
    "\n",
    "const retrievalChain = RunnableSequence.from([\n",
    "  {\n",
    "    context: documentRetrievalChain,\n",
    "    question: (input) => input.question,\n",
    "  },\n",
    "  answerGenerationPrompt,\n",
    "  model,\n",
    "  new StringOutputParser(),\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note: \n",
    "\n",
    "- In the `RunnableSequence.from` method, objects are automatically coerced into `RunnableMap`s, so there is no need to use the initializer method.\n",
    "- Because we want to pass `question` into both the `documentRetrievalChain` to fetch relevant documents as well as the `answerGenerationPrompt`, we add a second property to the `RunnableMap` called `question` that extracts just the `question` field from the original input to the map. This means that the answer generation prompt gets an object with both properties.\n",
    "\n",
    "Because this pattern is so common, there is a helper called `RunnablePassthrough.assign()` that we can use which adds new properties to a `RunnableMap` while passing through all existing properties. You could thus rewrite the above like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnablePassthrough } from \"npm:langchain@0.0.201/runnables\";\n",
    "\n",
    "const retrievalChain = RunnableSequence.from([\n",
    "  RunnablePassthrough.assign({\n",
    "    context: documentRetrievalChain,\n",
    "  }),\n",
    "  answerGenerationPrompt,\n",
    "  model,\n",
    "  new StringOutputParser(),\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try it end-to-end!\n",
    "\n",
    "// RunnableContext might be nice to add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prerequisites for this course are familiarity with basic probability and statistics, basic linear algebra, and some programming knowledge, mostly in MATLAB or Octave. Familiarity with random variables, expectation, variance, matrix operations, and vectors is also assumed. Additional review of prerequisites will be provided during the course.\n"
     ]
    }
   ],
   "source": [
    "const answer = await retrievalChain.invoke({\n",
    "  question: \"What are the prerequisites for this course?\"\n",
    "});\n",
    "\n",
    "console.log(answer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! That looks pretty good.\n",
    "\n",
    "This is great, but what if we want to ask a followup question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Students from various backgrounds including statistics, iCME, synthesis, aero/astro, and MSNE\n",
      "- Goal of the project is to produce a publishable piece of research in machine learning\n",
      "- Previous student projects included applications of learning algorithms to control a snake robot, improving learning algorithms, flying autonomous aircraft, computer vision algorithms, Netflix rankings, medical robots, neuroscience, fMRI data analysis, market makings, and more\n"
     ]
    }
   ],
   "source": [
    "const followupAnswer = await retrievalChain.invoke({\n",
    "  question: \"Can you list them in bullet point form?\"\n",
    "});\n",
    "\n",
    "console.log(followupAnswer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It listed items in bullet point form, but none of them were prerequisites to the course! \n",
    "\n",
    "This occurs because LLMs do not have an innate sense of memory, and since we're not passing in any chat history as context, the LLM doesn't know what \"them\" referes to. We can update our prompt to take chat history into account as well, but we have a more fundamental problem: our vectorstore needs to return relevant documents too. Here's what happens if we try to query our vectorstore with the current followup question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc>\n",
      "at me, and that won't show, okay?   \n",
      "Let's see. I also handed out this — ther e were two handouts I hope most of you have,  \n",
      "course information handout. So let me just sa y a few words about parts of these. On the  \n",
      "third page, there's a section that says Online Resources.   \n",
      "Oh, okay. Louder? Actually, could you turn  up the volume? Testing. Is this better?  \n",
      "Testing, testing. Okay, cool. Thanks.\n",
      "</doc>\n",
      "<doc>\n",
      "and write out, was learned using one of  these reinforcement learning algorithms.   \n",
      "Just a word about that: The basic idea behi nd a reinforcement learning algorithm is this  \n",
      "idea of what's called a reward  function. What we have to  think about is imagine you're  \n",
      "trying to train a dog. So every time y our dog does something good, you say, \"Good dog,\"  \n",
      "and you reward the dog. Every time your dog does something bad, you go, \"Bad dog,\"  \n",
      "right? And hopefully, over time, your dog will lear n to do the right things to get more of  \n",
      "the positive rewards, to get mo re of the \"Good dogs\" and to ge t fewer of the \"Bad dogs.”\n",
      "</doc>\n",
      "<doc>\n",
      "many biologers are there here? Wow, just a  few, not many. I'm surprised. Anyone from  \n",
      "statistics? Okay, a few. So where are the rest of you from?   \n",
      "Student :  iCME.   \n",
      "Instructor (Andrew Ng) :  Say again?   \n",
      "Student :  iCME.   \n",
      "Instructor (Andrew Ng) :  iCME. Cool.   \n",
      "Student :  [Inaudible].   \n",
      "Instructor (Andrew Ng) :  Civi and what else?   \n",
      "Student :  [Inaudible]   \n",
      "Instructor (Andrew Ng) :  Synthesis, [inaudible] systems. Yeah, cool.   \n",
      "Student :  Chemi.   \n",
      "Instructor (Andrew Ng) :  Chemi. Cool.   \n",
      "Student :  [Inaudible].   \n",
      "Instructor (Andrew Ng) :  Aero/astro. Yes, right. Yeah, okay, cool. Anyone else?   \n",
      "Student :  [Inaudible].   \n",
      "Instructor (Andrew Ng) :  Pardon? MSNE. All ri ght. Cool. Yeah.   \n",
      "Student :  [Inaudible].   \n",
      "Instructor (Andrew Ng) :  Pardon?   \n",
      "Student :  [Inaudible].   \n",
      "Instructor (Andrew Ng) :  Endo —   \n",
      "Student :  [Inaudible].   \n",
      "Instructor (Andrew Ng) :  Oh, I see, industry. Okay. Cool. Great, great. So as you can  \n",
      "tell from a cross-section of th is class, I think we're a very diverse audience in this room,  \n",
      "and that's one of the things that makes this  class fun to teach and fun to be in, I think.\n",
      "</doc>\n",
      "<doc>\n",
      "And let's see. Oh, and the goal of the projec t should really be for you to do a publishable  \n",
      "piece of research in machine learning, okay?   \n",
      "And if you go to the course website, you'll actuall y find a list of the projects that students  \n",
      "had done last year. And so I'm holding the li st in my hand. You can  go home later and  \n",
      "take a look at it online.   \n",
      "But reading down this list, I see  that last year, there were st udents that ap plied learning  \n",
      "algorithms to control a snake robot. Ther e was a few projects  on improving learning  \n",
      "algorithms. There's a project on flying autonomous  aircraft. There was  a project actually  \n",
      "done by our TA Paul on improvi ng computer vision algorithms  using machine learning.   \n",
      "There are a couple of project s on Netflix rankings using  learning algorithms; a few  \n",
      "medical robots; ones on segmenting [inaudibl e] to segmenting pieces of the body using  \n",
      "learning algorithms; one on musical instrume nt detection; anot her on irony sequence  \n",
      "alignment; and a few algorithms on understandin g the brain neuroscience, actually quite a  \n",
      "few projects on neuroscience;  a couple of projects on unde scending fMRI data on brain  \n",
      "scans, and so on; another project on market  makings, the financial trading. There was an  \n",
      "interesting project on trying to  use learning algorithms to decide what is it that makes a  \n",
      "person's face physically attractive. There's a  learning algorithm on op tical illusions, and  \n",
      "so on.\n",
      "</doc>\n"
     ]
    }
   ],
   "source": [
    "const docs = await documentRetrievalChain.invoke({\n",
    "  question: \"Can you list them in bullet point form?\"\n",
    "});\n",
    "\n",
    "console.log(docs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we don't get anything relevant to the prerequisites of CS229.\n",
    "\n",
    "The solution is to dereference the user's question into a rephrased standalone question. How? With an LLM of course!\n",
    "\n",
    "First, we'll construct a new prompt with a `MessagesPlaceholder` where we can later inject or pass chat history messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MessagesPlaceholder } from \"npm:langchain@0.0.201/prompts\";\n",
    "\n",
    "const REPHRASE_QUESTION_SYSTEM_TEMPLATE = `Using the provided chat history as context, rephrase the following question to be a standalone question that has no external references.\n",
    "\n",
    "Do not respond with anything other than a rephrased standalone question.`;\n",
    "\n",
    "const rephraseQuestionChainPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", REPHRASE_QUESTION_SYSTEM_TEMPLATE],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\"human\", \"Now, answer the following question:\\n{question}\"],\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we'll create a simple chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "const rephraseQuestionChain = RunnableSequence.from([\n",
    "  rephraseQuestionChainPrompt,\n",
    "  new ChatOpenAI({ temperature: 0, modelName: \"gpt-3.5-turbo-1106\" }),\n",
    "  new StringOutputParser(),\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running this chain on our followup question. Note that `MessagesPlaceholder` is itself a parameter in our prompt that accepts a list of chat messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"What are the prerequisites for this course?\"\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { HumanMessage, AIMessage } from \"npm:langchain@0.0.201/schema\";\n",
    "\n",
    "const originalQuestion = \"What are the prerequisites for this course?\";\n",
    "\n",
    "const originalAnswer = await retrievalChain.invoke({\n",
    "  question: originalQuestion\n",
    "});\n",
    "\n",
    "const chatHistory = [\n",
    "  new HumanMessage(originalQuestion),\n",
    "  new AIMessage(originalAnswer),\n",
    "];\n",
    "\n",
    "await rephraseQuestionChain.invoke({\n",
    "  question: \"Can you list them in bullet point form?\",\n",
    "  history: chatHistory,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! That question makes sense on its own. Now, let's put it all together with a new chain that takes chat history as input!\n",
    "\n",
    "First, here's our document retrieval and formatting chain again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "const convertDocsToString = (documents: Document[]): string => {\n",
    "  return documents.map((document) => `<doc>\\n${document.pageContent}\\n</doc>`).join(\"\\n\");\n",
    "};\n",
    "\n",
    "const documentRetrievalChain = RunnableSequence.from([\n",
    "  (input) => input.standalone_question,\n",
    "  retriever,\n",
    "  convertDocsToString,\n",
    "]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly track and inject chat history, we're going to use a `MessageHistory` object, then wrap our chain in a manager that will automatically update the history, called `RunnableWithMessageHistory`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableWithMessageHistory } from \"npm:langchain@0.0.201/runnables\";\n",
    "import { ChatMessageHistory } from \"npm:langchain@0.0.201/memory\";\n",
    "\n",
    "const ANSWER_CHAIN_SYSTEM_TEMPLATE = `You are an experienced researcher, expert at interpreting and answering questions based on provided sources.\n",
    "Using the below provided context and chat history, answer the user's question to the best of your ability using only the resources provided. Be concise!\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>`;\n",
    "\n",
    "const answerGenerationChainPrompt = ChatPromptTemplate.fromMessages([\n",
    "  [\"system\", ANSWER_CHAIN_SYSTEM_TEMPLATE],\n",
    "  new MessagesPlaceholder(\"history\"),\n",
    "  [\"human\", \"Now, answer this question using the previous context and chat history:\\n{standalone_question}\"]\n",
    "]);\n",
    "\n",
    "const messageHistory = new ChatMessageHistory();\n",
    "\n",
    "const conversationalRetrievalChain = RunnableSequence.from([\n",
    "  RunnablePassthrough.assign({\n",
    "    standalone_question: rephraseQuestionChain,\n",
    "  }),\n",
    "  RunnablePassthrough.assign({\n",
    "    context: documentRetrievalChain,\n",
    "  }),\n",
    "  answerGenerationChainPrompt,\n",
    "  new ChatOpenAI({ modelName: \"gpt-3.5-turbo\" }),\n",
    "  new StringOutputParser(),\n",
    "]);\n",
    "\n",
    "// Maybe simplify with explicit history passing\n",
    "const conversationalRetrievalChainWithHistory = new RunnableWithMessageHistory({\n",
    "  runnable: conversationalRetrievalChain,\n",
    "  getMessageHistory: (_sessionId) => messageHistory,\n",
    "  inputMessagesKey: \"question\",\n",
    "  historyMessagesKey: \"history\",\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prerequisites for this course include basic probability and statistics knowledge, as well as familiarity with linear algebra concepts. Students should be familiar with random variables, expectation, variance, matrices, vectors, matrix multiplication, and matrix inverse. Previous undergraduate courses in statistics and linear algebra should be sufficient preparation.\n"
     ]
    }
   ],
   "source": [
    "const originalQuestion = \"What are the prerequisites for this course?\";\n",
    "\n",
    "const originalAnswer = await conversationalRetrievalChainWithHistory.invoke({\n",
    "  question: originalQuestion,\n",
    "}, {\n",
    "  configurable: { sessionId: \"unused\" }\n",
    "});\n",
    "\n",
    "const finalResult = await conversationalRetrievalChainWithHistory.invoke({\n",
    "  question: \"Can you list them in bullet point form?\",\n",
    "}, {\n",
    "  configurable: { sessionId: \"unused\" }\n",
    "});\n",
    "\n",
    "console.log(finalResult);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval is a very deep topic, and there's no one-size fits all approach for loading, splitting, and querying your data. We encourage you to modify the above prompts and parameters for different models and data types.\n",
    "\n",
    "In the final section, we'll show how to put this retrieval chain into production, including some interactions with web APIs and streaming intermediate steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nb_converter": "script",
   "pygments_lexer": "typescript",
   "version": "5.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
